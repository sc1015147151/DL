{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "import os\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "import argparse\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from keras import backend as K \n",
    "from Models import *\n",
    "from Models.utils import *\n",
    "#coding=utf-8\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np \n",
    "from keras import *\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.preprocessing.image import img_to_array  \n",
    "from keras.callbacks import ModelCheckpoint ,TensorBoard\n",
    "from SegNet0 import *\n",
    "from SegNet import *\n",
    "from SegNet2 import *\n",
    "from SegNet1 import *\n",
    "from FCN32 import *\n",
    "from Models.utils import *\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from PIL import Image  \n",
    "import matplotlib.pyplot as plt  \n",
    "import cv2\n",
    "import random\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm  \n",
    "from keras import backend as K \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import time\n",
    "import gdal\n",
    "seed = 7  \n",
    "np.random.seed(seed)  \n",
    "# data for training  \n",
    "from keras.applications import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network model...\n",
      "[INFO] model loaded\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:55: error: (-4) Failed to allocate 33554432 bytes in function cv::OutOfMemoryError\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3b1318da3329>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mmask_whole\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_whole\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'UNET'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-3b1318da3329>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(key, stride)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mpadding_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadding_h\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mpadding_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadding_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;31m#print(b1/np.max(b1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mmask_whole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadding_h\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:55: error: (-4) Failed to allocate 33554432 bytes in function cv::OutOfMemoryError\n"
     ]
    }
   ],
   "source": [
    "def predict(key,stride=256):\n",
    "    method = {\n",
    "              'FCN32':FCN32,\n",
    "              'SegNet0': SegNet0,\n",
    "              'SegNet1': SegNet1,\n",
    "              'SegNet2': SegNet2,\n",
    "              'SegNet': SegNet}\n",
    "    key='UNET'\n",
    "    # load the trained convolutional neural network\n",
    "    print(\"[INFO] loading network model...\")\n",
    "    try:\n",
    "        model = load_model('D:\\Python\\seg-data/model/%s_model.h5' % key)\n",
    "    except:\n",
    "        model = method[key]() # 有自定义层时，不能直接加载模型\n",
    "        model.load_weights('D:\\Python\\seg-data/model/%s_model.h5' % key)\n",
    "    print('[INFO] model loaded')\n",
    "    image_size=stride\n",
    "    TEST_SET=['2019.tif']\n",
    "    predir=r'D:\\Python\\seg-data\\data_MB/'\n",
    "    for n in range(len(TEST_SET)):\n",
    "        tif_img = gdal.Open(predir+TEST_SET[n])\n",
    "        tif_w = tif_img.RasterXSize #栅格矩阵的列数\n",
    "        tif_h = tif_img.RasterYSize\n",
    "        tif_data=tif_img.ReadAsArray(0,0,tif_w,tif_h)\n",
    "        tif_d=tif_data.shape[0]\n",
    "        tif_data=np.array(tif_data, dtype=float)\n",
    "        image=cv2.merge(tif_data)\n",
    "        #print(np.sum(tif_data[0]))\n",
    "        #plt.imshow(tif_data[0])\n",
    "        h,w,_ = image.shape\n",
    "        padding_h = (h//stride + 1) * stride \n",
    "        padding_w = (w//stride + 1) * stride\n",
    "        padding_img = np.zeros((padding_h,padding_w,_))\n",
    "        padding_img[0:h,0:w,:] = image[:,:,:]\n",
    "        b1,b2,b3,b4=cv2.split(padding_img) \n",
    "        #print(b1/np.max(b1))\n",
    "        mask_whole = np.zeros((padding_h,padding_w))\n",
    "        for i in range(padding_h//stride):\n",
    "            for j in range(padding_w//stride):\n",
    "                crop = padding_img[i*stride:i*stride+image_size,j*stride:j*stride+image_size,:]\n",
    "                ch,cw,_ = crop.shape\n",
    "                print(crop.shape)\n",
    "                if (ch != 256 or cw != 256):\n",
    "                    print ('invalid size!')\n",
    "                    continue\n",
    "                crop = np.expand_dims(crop, axis=0)\n",
    "                try:\n",
    "                    pred = model.predict_classes(crop,verbose=0)\n",
    "                    pred_prob = model.predict_proba(crop,verbose=1)\n",
    "                    print ('trying\\n')\n",
    "                except AttributeError as e:\n",
    "                    #print (crop.shape,np.sum(crop),'\\n')\n",
    "                    pred = model.predict(crop)\n",
    "                    #print((pred+0.5 ).astype(np.int32))\n",
    "                    pred=np.argmax(pred,axis=2).astype(np.float) \n",
    "                    #print(pred)\n",
    "                \n",
    "                pred = pred.reshape((256,256))\n",
    "                mask_whole[i*stride:i*stride+image_size,j*stride:j*stride+image_size] = pred[:,:]\n",
    "    plt.imshow(mask_whole,cmap='gray')\n",
    "predict(key='UNET',stride=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
